{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.contrib.framework.python.ops.variables import get_or_create_global_step\n",
    "from inception_resnet_v2 import inception_resnet_v2, inception_resnet_v2_arg_scope\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib\n",
    "from CNN_data_preprocess import get_label_mapping, get_files, bottle_neck_process\n",
    "slim = tf.contrib.slim\n",
    "from color_filter import red_filtered\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_file = './model_file/inception_resnet_v2_2016_08_30.ckpt'\n",
    "label_file = './labels.txt'\n",
    "train_file = './Data5/'\n",
    "bottle_neck_file = './middle_data/bottle_neck5_timestamp_filter/'\n",
    "save_model_file = './model_file/inception_resnet_v2_for5_filter'\n",
    "last_layer_file = './middle_data/last_layer5_filter/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_graph():\n",
    "images = tf.placeholder(tf.float32, shape=(None, 480, 720, 3))\n",
    "labels = tf.placeholder(tf.int32, shape=(None,))\n",
    "\n",
    "# restore from the inception_resnet model\n",
    "with slim.arg_scope(inception_resnet_v2_arg_scope()):\n",
    "        _, end_points = inception_resnet_v2(images, num_classes = 1001, is_training = False) \n",
    "\n",
    "# extract the before_logit tensor from the extracted model\n",
    "before_logit = end_points['PreLogitsFlatten']\n",
    "\n",
    "\n",
    "# define a placeholder for training from the bottle, not from the beginning.\n",
    "bottle_neck = tf.placeholder(tf.float32, shape=(None,1536 * 2))\n",
    "\n",
    "# now define the fine tune part of the graph\n",
    "with tf.name_scope('my_fine_tune') as scope:\n",
    "#     dropout = tf.layers.dropout(bottle_neck, rate=0.3, name='dropout')\n",
    "    batch_norm1 = tf.layers.batch_normalization(bottle_neck, name='batch_norm1')\n",
    "    dropout1 = tf.layers.dropout(batch_norm1, rate=0.3, name='dropout1')\n",
    "    dense1 = tf.layers.dense(dropout1, 512, activation=tf.nn.relu, name='dense1')\n",
    "    batch_norm2 = tf.layers.batch_normalization(dense1, name='batch_norm2')\n",
    "    dropout2 = tf.layers.dropout(batch_norm2, rate = 0.3, name='dropout2')\n",
    "    dense2 = tf.layers.dense(dropout2, 128, activation=tf.nn.relu, name='dense2')\n",
    "    batch_norm3 = tf.layers.batch_normalization(dense2, name='batch_norm3')\n",
    "    dropout3 = tf.layers.dropout(batch_norm3, rate = 0.3, name='dropout3')\n",
    "    logits = tf.layers.dense(dropout3, 3, name='logits')\n",
    "\n",
    "    x_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "    loss = tf.reduce_mean(x_entropy, name='loss')\n",
    "    correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    # extract variables that need to be trained\n",
    "    weight1, bias1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'dense1')\n",
    "    weight2, bias2 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'logits')\n",
    "    variables_to_train = [weight1, weight2, bias1, bias2]\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = slim.learning.create_train_op(loss, optimizer, variables_to_train=variables_to_train)\n",
    "\n",
    "# defiine the name scope we don't need to restore from inception_resnet\n",
    "exclude = ['InceptionResnetV2/AuxLogits', 'InceptionResnetV2/Logits',\n",
    "           'my_fine_tune/','dense','logits','batch_norm']\n",
    "\n",
    "variables_to_restore = slim.get_variables_to_restore(exclude = exclude)\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "init = tf.global_variables_initializer()\n",
    "# builder = tf.saved_model.builder.SavedModelBuilder(save_model_file)\n",
    "\n",
    "#     return images, labels, before_logit, bottle_neck,batch_norm2, loss, accuracy, train_op, saver, init, builder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(before_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the data before the fine tune layer\n",
    "def get_bottle_neck_data(sess, before_logit, images, train_file, bottle_neck_file, label_file, hsv = False):\n",
    "    id2label, label2id = get_label_mapping(label_file)\n",
    "    for i in id2label:\n",
    "        read_dir = train_file + i\n",
    "        des_dir = bottle_neck_file + i + '/'\n",
    "        os.mkdir(des_dir)\n",
    "        \n",
    "        files = get_files(read_dir)\n",
    "        for f in files:\n",
    "            img = mpimg.imread(f).reshape(1,480,720,3) / 255\n",
    "            img1 = cv2.imread(f)\n",
    "            img1=red_filtered(img1)[1].reshape(1,480,720,3) / 255\n",
    "            if(hsv):\n",
    "                img = matplotlib.colors.rgb_to_hsv(img)\n",
    "            bottle = sess.run(before_logit, feed_dict={images:img})\n",
    "            bottle1 = sess.run(before_logit, feed_dict={images:img1})\n",
    "            bottle = np.concatenate((bottle, bottle1), axis = 1)\n",
    "            print(bottle.shape)\n",
    "            np.save(des_dir + f[len(read_dir):],  bottle)\n",
    "            print('save the bottle neck file ' + f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottle_neck_data_timestamp(sess, before_logit, images, train_file, bottle_neck_file, label_file, hsv = False):\n",
    "    os.mkdir(bottle_neck_file)\n",
    "    folders = listdir_nohidden(train_file)\n",
    "    print(bottle_neck_file)\n",
    "    for folder in folders:\n",
    "        train_actual = train_file + folder + '/'\n",
    "        bottle_neck_actual = bottle_neck_file + folder + '/'\n",
    "        print(train_actual)\n",
    "        print(bottle_neck_actual)\n",
    "        os.mkdir(bottle_neck_actual)\n",
    "        get_bottle_neck_data(sess, before_logit, images, train_actual, bottle_neck_actual, label_file, hsv = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_graph(sess):\n",
    "#     images, labels, before_logit, bottle_neck, batch_norm2, loss, accuracy, train_op, saver, init, builder = model_list\n",
    "    \n",
    "    sess.run(init)\n",
    "    saver.restore(sess, checkpoint_file)\n",
    "\n",
    "    # if there is no dir for the bottle data, then get the data first.\n",
    "    if(os.path.isdir(bottle_neck_file) is not True):\n",
    "        os.mkdir(bottle_neck_file)\n",
    "        get_bottle_neck_data(sess, before_logit, images, train_file, bottle_neck_file, label_file, hsv = False)\n",
    "\n",
    "    # get training data from bottle_neck file, and train.\n",
    "    bottle_neck_processor = bottle_neck_process(bottle_neck_file, label_file) \n",
    "    for i in range(2000):\n",
    "        inputs, groud_truth = bottle_neck_processor.next_batch(128)\n",
    "        train_loss, train_accuracy = sess.run([train_op, accuracy], feed_dict={bottle_neck: inputs, \n",
    "                                                                             labels: groud_truth})\n",
    "\n",
    "        if(i % 50 == 0):\n",
    "            val_loss, val_accuracy = sess.run([loss, accuracy],\n",
    "                                              feed_dict={bottle_neck: bottle_neck_processor.val_inputs,\n",
    "                                                         labels: bottle_neck_processor.val_labels})\n",
    "        \n",
    "            print('####################################')\n",
    "            print('the training loss after ' + str(i) + ' iterations is: ' + str(train_loss))\n",
    "            print('the training accuracy after ' + str(i) + ' iterations is: ' + str(train_accuracy))\n",
    "            print('the val loss after ' + str(i) + ' iterations is: ' + str(val_loss))\n",
    "            print('the val accuracy after ' + str(i) + ' iterations is: ' + str(val_accuracy))\n",
    "            print('-------------')\n",
    "            \n",
    "            for i in bottle_neck_processor.id2label:\n",
    "                val_accuracy = sess.run([accuracy],\n",
    "                                      feed_dict={bottle_neck: bottle_neck_processor.val_inputs_each[i],\n",
    "                                                 labels: bottle_neck_processor.val_labels_each[i]})\n",
    "                print(i + ': the val accuracy is: '  + str(val_accuracy))\n",
    "        \n",
    "#         after the training process finished, store the model to a '.pb' version file.\n",
    "    builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.TRAINING],\n",
    "                                         signature_def_map=None, assets_collection=None)\n",
    "    \n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    config = tf.ConfigProto()\n",
    "    config.allow_soft_placement = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "#         train_graph(sess)\n",
    "        sess.run(init)\n",
    "        saver.restore(sess, checkpoint_file)\n",
    "        get_bottle_neck_data_timestamp(sess, before_logit, images, train_file, bottle_neck_file, label_file, hsv = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
